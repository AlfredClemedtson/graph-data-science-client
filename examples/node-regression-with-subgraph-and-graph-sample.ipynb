{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69f4a041",
   "metadata": {},
   "source": [
    "# Node Regression pipeline\n",
    "\n",
    "This notebook exemplifies using a Node Regression pipeline.\n",
    "It also contains many examples of using\n",
    "\n",
    "- Convenience objects\n",
    "- Subgraph projection\n",
    "- Graph sample projection\n",
    "\n",
    "It is written in pure Python, to showcase the GDS Python Client's ability to abstract away from Cypher queries.\n",
    "\n",
    "\n",
    "## The dataset\n",
    "\n",
    "Our input graph represents Wikipedia pages on particular topics, and how they link to each other:\n",
    "\n",
    "- Chameleons\n",
    "- Squirrels\n",
    "- Crocodiles\n",
    "\n",
    "The features are presences of certain informative nouns in the text of the page.\n",
    "The target is the average monthly traffic of the page.\n",
    "\n",
    "The dataset was first published in _Multi-scale Attributed Node Embedding_ by B. Rozemberczki, C. Allen and R. Sarkar, [eprint 1909.13021](https://arxiv.org/abs/1909.13021).\n",
    "The version hosted here was taken from [SNAP](https://snap.stanford.edu/data/wikipedia-article-networks.html) on 2022-11-14.\n",
    "\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "In order to run this pipeline, you must have the following:\n",
    "\n",
    "- A running Neo4j DBMS with\n",
    "  - a recent version of Graph Data Science installed\n",
    "  - a recent version of APOC installed\n",
    "\n",
    "These requirements are satisfied if you have an AuraDS instance active and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# First, we must install the GDS Python Client\n",
    "%pip install graphdatascience"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.3\n"
     ]
    }
   ],
   "source": [
    "# Then, we connect to our Neo4j DBMS hosting the Graph Data Science library\n",
    "from graphdatascience import GraphDataScience\n",
    "\n",
    "# Replace with the actual connection URI and credentials\n",
    "NEO4J_CONNECTION_URI = \"neo4j+s://<aurads-instance>.databases.neo4j.io\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"\"\n",
    "\n",
    "\n",
    "# Connect to Neo4j and create the GraphDataScience object\n",
    "gds = GraphDataScience(NEO4J_CONNECTION_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD), aura_ds=True)\n",
    "\n",
    "# Test our connection and print the Graph Data Science library version\n",
    "print(gds.version())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: []\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "\n",
    "# The dataset is sourced from this GitHub repository\n",
    "baseUrl = \"https://github.com/Mats-SX/gdsclient/raw/regression-notebook/examples/datasets/wikipedia-animals-pages\"\n",
    "\n",
    "# Constraints to speed up importing\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    CREATE CONSTRAINT chameleons\n",
    "    FOR (c:Chameleon)\n",
    "    REQUIRE c.id IS NODE KEY\n",
    "\"\"\"\n",
    ")\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    CREATE CONSTRAINT crocodiles\n",
    "    FOR (c:Crocodile)\n",
    "    REQUIRE c.id IS NODE KEY\n",
    "\"\"\"\n",
    ")\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    CREATE CONSTRAINT squirrels\n",
    "    FOR (s:Squirrel)\n",
    "    REQUIRE s.id IS NODE KEY\n",
    "\"\"\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: []\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create nodes and relationships\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM $baseUrl + '/chameleon/musae_chameleon_edges.csv' AS row\n",
    "    MERGE (c1:Chameleon {id: row.id1})\n",
    "    MERGE (c2:Chameleon {id: row.id2})\n",
    "    MERGE (c1)-[:LINK]->(c2)\n",
    "\"\"\",\n",
    "    {\"baseUrl\": baseUrl},\n",
    ")\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM $baseUrl + '/crocodile/musae_crocodile_edges.csv' AS row\n",
    "    MERGE (c1:Crocodile {id: row.id1})\n",
    "    MERGE (c2:Crocodile {id: row.id2})\n",
    "    MERGE (c1)-[:LINK]->(c2)\n",
    "\"\"\",\n",
    "    {\"baseUrl\": baseUrl},\n",
    ")\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM $baseUrl + '/squirrel/musae_squirrel_edges.csv' AS row\n",
    "    MERGE (s1:Squirrel {id: row.id1})\n",
    "    MERGE (s2:Squirrel {id: row.id2})\n",
    "    MERGE (s1)-[:LINK]->(s2)\n",
    "\"\"\",\n",
    "    {\"baseUrl\": baseUrl},\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: []\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create target properties\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM $baseUrl + '/chameleon/musae_chameleon_target.csv' AS row\n",
    "    MATCH (c:Chameleon {id: row.id})\n",
    "    SET c.target = toInteger(row.target)\n",
    "\"\"\",\n",
    "    {\"baseUrl\": baseUrl},\n",
    ")\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM $baseUrl + '/crocodile/musae_crocodile_target.csv' AS row\n",
    "    MATCH (c:Crocodile {id: row.id})\n",
    "    SET c.target = toInteger(row.target)\n",
    "\"\"\",\n",
    "    {\"baseUrl\": baseUrl},\n",
    ")\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM $baseUrl + '/squirrel/musae_squirrel_target.csv' AS row\n",
    "    MATCH (s:Squirrel {id: row.id})\n",
    "    SET s.target = toInteger(row.target)\n",
    "\"\"\",\n",
    "    {\"baseUrl\": baseUrl},\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: []\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature vectors\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    CALL apoc.load.json($baseUrl + '/chameleon/musae_chameleon_features.json') YIELD value\n",
    "    WITH value, keys(value) AS keys\n",
    "    UNWIND keys AS key\n",
    "    WITH value[key] AS feature, key\n",
    "    MATCH (c:Chameleon {id: key})\n",
    "    SET c.features = feature\n",
    "\"\"\",\n",
    "    {\"baseUrl\": baseUrl},\n",
    ")\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    CALL apoc.load.json($baseUrl + '/crocodile/musae_crocodile_features.json') YIELD value\n",
    "    WITH value, keys(value) AS keys\n",
    "    UNWIND keys AS key\n",
    "    WITH value[key] AS feature, key\n",
    "    MATCH (c:Crocodile {id: key})\n",
    "    SET c.features = feature\n",
    "\"\"\",\n",
    "    {\"baseUrl\": baseUrl},\n",
    ")\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    CALL apoc.load.json($baseUrl + '/squirrel/musae_squirrel_features.json') YIELD value\n",
    "    WITH value, keys(value) AS keys\n",
    "    UNWIND keys AS key\n",
    "    WITH value[key] AS feature, key\n",
    "    MATCH (c:Squirrel {id: key})\n",
    "    SET c.features = feature\n",
    "\"\"\",\n",
    "    {\"baseUrl\": baseUrl},\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparing the dataset for the pipeline\n",
    "\n",
    "In order to use the dataset, we must make sure that the feature dimension is consistent over the entire node sets.\n",
    "In their raw form, the feature vectors are of different lengths.\n",
    "To overcome this, we will use a one-hot encoding.\n",
    "We begin by learning the dictionaries of nouns across the node sets.\n",
    "We create a node to host the dictionary, then we use it to one-hot encode all feature vectors.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: []\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct one-hot dictionaries\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    MATCH (s:Chameleon)\n",
    "    WITH s.features AS features\n",
    "    UNWIND features AS feature\n",
    "    WITH feature\n",
    "      ORDER BY feature ASC\n",
    "    WITH collect(distinct feature) AS orderedTotality\n",
    "    CREATE (:Feature {animal: 'chameleon', totality: orderedTotality})\n",
    "    RETURN orderedTotality\n",
    "\"\"\"\n",
    ")\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    MATCH (s:Crocodile)\n",
    "    WITH s.features AS features\n",
    "    UNWIND features AS feature\n",
    "    WITH feature\n",
    "      ORDER BY feature ASC\n",
    "    WITH collect(distinct feature) AS orderedTotality\n",
    "    CREATE (:Feature {animal: 'crocodile', totality: orderedTotality})\n",
    "    RETURN orderedTotality\n",
    "\"\"\"\n",
    ")\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    MATCH (s:Squirrel)\n",
    "    WITH s.features AS features\n",
    "    UNWIND features AS feature\n",
    "    WITH feature\n",
    "      ORDER BY feature ASC\n",
    "    WITH collect(distinct feature) AS orderedTotality\n",
    "    CREATE (:Feature {animal: 'squirrel', totality: orderedTotality})\n",
    "    RETURN orderedTotality\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Do one-hot encoding\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    MATCH (f:Feature {animal: 'chameleon'})\n",
    "    MATCH (c:Chameleon)\n",
    "    SET c.features_one_hot = gds.alpha.ml.oneHotEncoding(f.totality, c.features)\n",
    "\"\"\"\n",
    ")\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    MATCH (f:Feature {animal: 'crocodile'})\n",
    "    MATCH (c:Crocodile)\n",
    "    SET c.features_one_hot = gds.alpha.ml.oneHotEncoding(f.totality, c.features)\n",
    "\"\"\"\n",
    ")\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    MATCH (f:Feature {animal: 'squirrel'})\n",
    "    MATCH (c:Squirrel)\n",
    "    SET c.features_one_hot = gds.alpha.ml.oneHotEncoding(f.totality, c.features)\n",
    "\"\"\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "2b954555",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "{code: Neo.ClientError.Procedure.ProcedureCallFailed} {message: Failed to invoke procedure `gds.graph.project`: Caused by: java.lang.IllegalArgumentException: A graph with name 'wiki_animals' already exists.}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mClientError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[0;32mIn [516]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# First, let's project our graph into the GDS Graph Catalog\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# We will use a native projection to begin with\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m G_animals, projection_result \u001B[38;5;241m=\u001B[39m \u001B[43mgds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproject\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mwiki_animals\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mChameleon\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSquirrel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCrocodile\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mLINK\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43morientation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mUNDIRECTED\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnodeProperties\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfeatures_one_hot\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtarget\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(projection_result[[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraphName\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnodeCount\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrelationshipCount\u001B[39m\u001B[38;5;124m\"\u001B[39m]])\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/graph/graph_project_runner.py:15\u001B[0m, in \u001B[0;36mGraphProjectRunner.__call__\u001B[0;34m(self, graph_name, node_spec, relationship_spec, **config)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28mself\u001B[39m, graph_name: \u001B[38;5;28mstr\u001B[39m, node_spec: Any, relationship_spec: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig: Any\n\u001B[1;32m     14\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Graph, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSeries[Any]\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m---> 15\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_query_runner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_query_with_logging\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCALL \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_namespace\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m($graph_name, $node_spec, $relationship_spec, $config)\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgraph_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mgraph_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnode_spec\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mnode_spec\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrelationship_spec\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mrelationship_spec\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mconfig\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msqueeze()\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Graph(graph_name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_query_runner, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_server_version), result\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/query_runner/arrow_query_runner.py:135\u001B[0m, in \u001B[0;36mArrowQueryRunner.run_query_with_logging\u001B[0;34m(self, query, params, database)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_query_with_logging\u001B[39m(\n\u001B[1;32m    132\u001B[0m     \u001B[38;5;28mself\u001B[39m, query: \u001B[38;5;28mstr\u001B[39m, params: Optional[Dict[\u001B[38;5;28mstr\u001B[39m, Any]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, database: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    133\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame:\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;66;03m# For now there's no logging support with Arrow queries.\u001B[39;00m\n\u001B[0;32m--> 135\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fallback_query_runner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_query_with_logging\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatabase\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/query_runner/neo4j_query_runner.py:85\u001B[0m, in \u001B[0;36mNeo4jQueryRunner.run_query_with_logging\u001B[0;34m(self, query, params, database)\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log(job_id, future, database)\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m future\u001B[38;5;241m.\u001B[39mexception():\n\u001B[0;32m---> 85\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m future\u001B[38;5;241m.\u001B[39mexception()  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     87\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m future\u001B[38;5;241m.\u001B[39mresult()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/concurrent/futures/thread.py:58\u001B[0m, in \u001B[0;36m_WorkItem.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfuture\u001B[38;5;241m.\u001B[39mset_exception(exc)\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/query_runner/neo4j_query_runner.py:58\u001B[0m, in \u001B[0;36mNeo4jQueryRunner.run_query\u001B[0;34m(self, query, params, database)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;66;03m# Though pandas support may be experimental in the `neo4j` package, it should always\u001B[39;00m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;66;03m# be supported in the `graphdatascience` package.\u001B[39;00m\n\u001B[1;32m     53\u001B[0m warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     55\u001B[0m     message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m^pandas support is experimental and might be changed or removed in future versions$\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     56\u001B[0m )\n\u001B[0;32m---> 58\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_df\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/neo4j/meta.py:85\u001B[0m, in \u001B[0;36mexperimental.<locals>.f__.<locals>.f_\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m warn\n\u001B[1;32m     84\u001B[0m warn(message, category\u001B[38;5;241m=\u001B[39mExperimentalWarning, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m---> 85\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/neo4j/work/result.py:401\u001B[0m, in \u001B[0;36mResult.to_df\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;124;03m\"\"\"Convert (the rest of) the result to a pandas DataFrame.\u001B[39;00m\n\u001B[1;32m    382\u001B[0m \n\u001B[1;32m    383\u001B[0m \u001B[38;5;124;03mThis method is only available if the `pandas` library is installed.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    397\u001B[0m \u001B[38;5;124;03mwithout warning. (See :ref:`filter-warnings-ref`)\u001B[39;00m\n\u001B[1;32m    398\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    399\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m--> 401\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mDataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, columns\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_keys)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/neo4j/work/result.py:365\u001B[0m, in \u001B[0;36mResult.values\u001B[0;34m(self, *keys)\u001B[0m\n\u001B[1;32m    356\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalues\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mkeys):\n\u001B[1;32m    357\u001B[0m     \u001B[38;5;124;03m\"\"\"Helper function that return the remainder of the result as a list of values lists.\u001B[39;00m\n\u001B[1;32m    358\u001B[0m \n\u001B[1;32m    359\u001B[0m \u001B[38;5;124;03m    See :class:`neo4j.Record.values`\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    363\u001B[0m \u001B[38;5;124;03m    :rtype: list\u001B[39;00m\n\u001B[1;32m    364\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 365\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [record\u001B[38;5;241m.\u001B[39mvalues(\u001B[38;5;241m*\u001B[39mkeys) \u001B[38;5;28;01mfor\u001B[39;00m record \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m]\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/neo4j/work/result.py:365\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    356\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalues\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mkeys):\n\u001B[1;32m    357\u001B[0m     \u001B[38;5;124;03m\"\"\"Helper function that return the remainder of the result as a list of values lists.\u001B[39;00m\n\u001B[1;32m    358\u001B[0m \n\u001B[1;32m    359\u001B[0m \u001B[38;5;124;03m    See :class:`neo4j.Record.values`\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    363\u001B[0m \u001B[38;5;124;03m    :rtype: list\u001B[39;00m\n\u001B[1;32m    364\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 365\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [record\u001B[38;5;241m.\u001B[39mvalues(\u001B[38;5;241m*\u001B[39mkeys) \u001B[38;5;28;01mfor\u001B[39;00m record \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m]\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/neo4j/work/result.py:187\u001B[0m, in \u001B[0;36mResult.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    185\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_record_buffer\u001B[38;5;241m.\u001B[39mpopleft()\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_streaming:\n\u001B[0;32m--> 187\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_connection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_discarding:\n\u001B[1;32m    189\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_discard()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/neo4j/io/_common.py:186\u001B[0m, in \u001B[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    184\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    185\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 186\u001B[0m         \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    188\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__on_error(exc)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/neo4j/io/_bolt4.py:309\u001B[0m, in \u001B[0;36mBolt4x0.fetch_message\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_server_state_manager\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m ServerStates\u001B[38;5;241m.\u001B[39mFAILED\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 309\u001B[0m     \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_failure\u001B[49m\u001B[43m(\u001B[49m\u001B[43msummary_metadata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ServiceUnavailable, DatabaseUnavailable):\n\u001B[1;32m    311\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/neo4j/io/_common.py:244\u001B[0m, in \u001B[0;36mResponse.on_failure\u001B[0;34m(self, metadata)\u001B[0m\n\u001B[1;32m    242\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(handler):\n\u001B[1;32m    243\u001B[0m     handler()\n\u001B[0;32m--> 244\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m Neo4jError\u001B[38;5;241m.\u001B[39mhydrate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmetadata)\n",
      "\u001B[0;31mClientError\u001B[0m: {code: Neo.ClientError.Procedure.ProcedureCallFailed} {message: Failed to invoke procedure `gds.graph.project`: Caused by: java.lang.IllegalArgumentException: A graph with name 'wiki_animals' already exists.}"
     ]
    }
   ],
   "source": [
    "# First, let's project our graph into the GDS Graph Catalog\n",
    "# We will use a native projection to begin with\n",
    "G_animals, projection_result = gds.graph.project(\n",
    "    \"wiki_animals\",\n",
    "    [\"Chameleon\", \"Squirrel\", \"Crocodile\"],\n",
    "    {\"LINK\": {\"orientation\": \"UNDIRECTED\"}},\n",
    "    nodeProperties=[\"features_one_hot\", \"target\"],\n",
    ")\n",
    "print(projection_result[[\"graphName\", \"nodeCount\", \"relationshipCount\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "e4c1526a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computeMillis     47\n",
      "componentCount     3\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# A good first analysis is to inspect connectivity\n",
    "# We use the WCC algorithm to see how many components we have\n",
    "wcc_result = gds.wcc.mutate(G_animals, mutateProperty=\"wcc_component\")\n",
    "\n",
    "print(wcc_result[[\"computeMillis\", \"componentCount\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "cbd63cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fromGraphName                wiki_animals\n",
      "nodeFilter            n.wcc_component = 0\n",
      "relationshipFilter                      *\n",
      "graphName             chameleon_component\n",
      "nodeCount                            2277\n",
      "relationshipCount                   72202\n",
      "projectMillis                          88\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Now, we can use the subgraph projection to separate out only one of the components\n",
    "G_chameleon, subgraph_result = gds.beta.graph.project.subgraph(\n",
    "    \"chameleon_component\",\n",
    "    G_animals,\n",
    "    \"n.wcc_component = 0\",  # Component with id 0 corresponds to the Chameleon part of the graph\n",
    "    \"*\",\n",
    ")\n",
    "\n",
    "print(subgraph_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "6d994ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#nodes: 2277\n",
      "#relationships: 72202\n",
      "Degree distribution\n",
      "=========================\n",
      "max     739.000000\n",
      "mean     31.709267\n",
      "min       1.000000\n",
      "p50      13.000000\n",
      "p75      31.000000\n",
      "p90      72.000000\n",
      "p95     154.000000\n",
      "p99     262.000000\n",
      "p999    657.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# With the graph object G_chameleon, we can inspect some statistics\n",
    "print(\"#nodes: \" + str(G_chameleon.node_count()))\n",
    "print(\"#relationships: \" + str(G_chameleon.relationship_count()))\n",
    "print(\"Degree distribution\")\n",
    "print(\"=\" * 25)\n",
    "print(G_chameleon.degree_distribution().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "2df00db8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "{code: Neo.ClientError.Procedure.ProcedureCallFailed} {message: Failed to invoke procedure `gds.alpha.pipeline.nodeRegression.addNodeProperty`: Caused by: java.lang.IllegalArgumentException: Could not find a procedure called gds.fastrp.mutate}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mClientError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[0;32mIn [509]\u001B[0m, in \u001B[0;36m<cell line: 22>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     18\u001B[0m chameleons_nr_training\u001B[38;5;241m.\u001B[39mconfigureAutoTuning(maxTrials\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Our input feature dimension is 3132\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# We can reduce the dimension to speed up training using a FastRP node embedding\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m \u001B[43mchameleons_nr_training\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maddNodeProperty\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfastRP\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43membeddingDimension\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpropertyRatio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.8\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeatureProperties\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfeatures_one_hot\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmutateProperty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfrp_embedding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandomSeed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m420\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# And finally we select what features the model should be using\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# We rely on the FastRP embedding solely, because it encapsulates the one-hot encoded source features\u001B[39;00m\n\u001B[1;32m     33\u001B[0m chameleons_nr_training\u001B[38;5;241m.\u001B[39mselectFeatures(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrp_embedding\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/pipeline/training_pipeline.py:37\u001B[0m, in \u001B[0;36mTrainingPipeline.addNodeProperty\u001B[0;34m(self, procedure_name, **config)\u001B[0m\n\u001B[1;32m     31\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_query_prefix()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124maddNodeProperty($pipeline_name, $procedure_name, $config)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     32\u001B[0m params \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpipeline_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname(),\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprocedure_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: procedure_name,\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfig\u001B[39m\u001B[38;5;124m\"\u001B[39m: config,\n\u001B[1;32m     36\u001B[0m }\n\u001B[0;32m---> 37\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_query_runner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msqueeze()\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/query_runner/arrow_query_runner.py:129\u001B[0m, in \u001B[0;36mArrowQueryRunner.run_query\u001B[0;34m(self, query, params, database)\u001B[0m\n\u001B[1;32m    125\u001B[0m         endpoint \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgds.beta.graph.relationships.stream\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_arrow_property_get(graph_name, endpoint, {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrelationship_types\u001B[39m\u001B[38;5;124m\"\u001B[39m: relationship_types})\n\u001B[0;32m--> 129\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fallback_query_runner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatabase\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/gitRoots/graph-data-science-client/graphdatascience/query_runner/neo4j_query_runner.py:58\u001B[0m, in \u001B[0;36mNeo4jQueryRunner.run_query\u001B[0;34m(self, query, params, database)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;66;03m# Though pandas support may be experimental in the `neo4j` package, it should always\u001B[39;00m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;66;03m# be supported in the `graphdatascience` package.\u001B[39;00m\n\u001B[1;32m     53\u001B[0m warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     55\u001B[0m     message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m^pandas support is experimental and might be changed or removed in future versions$\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     56\u001B[0m )\n\u001B[0;32m---> 58\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_df\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/neo4j/meta.py:85\u001B[0m, in \u001B[0;36mexperimental.<locals>.f__.<locals>.f_\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m warn\n\u001B[1;32m     84\u001B[0m warn(message, category\u001B[38;5;241m=\u001B[39mExperimentalWarning, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m---> 85\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/neo4j/work/result.py:401\u001B[0m, in \u001B[0;36mResult.to_df\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;124;03m\"\"\"Convert (the rest of) the result to a pandas DataFrame.\u001B[39;00m\n\u001B[1;32m    382\u001B[0m \n\u001B[1;32m    383\u001B[0m \u001B[38;5;124;03mThis method is only available if the `pandas` library is installed.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    397\u001B[0m \u001B[38;5;124;03mwithout warning. (See :ref:`filter-warnings-ref`)\u001B[39;00m\n\u001B[1;32m    398\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    399\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m--> 401\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mDataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, columns\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_keys)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/neo4j/work/result.py:365\u001B[0m, in \u001B[0;36mResult.values\u001B[0;34m(self, *keys)\u001B[0m\n\u001B[1;32m    356\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalues\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mkeys):\n\u001B[1;32m    357\u001B[0m     \u001B[38;5;124;03m\"\"\"Helper function that return the remainder of the result as a list of values lists.\u001B[39;00m\n\u001B[1;32m    358\u001B[0m \n\u001B[1;32m    359\u001B[0m \u001B[38;5;124;03m    See :class:`neo4j.Record.values`\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    363\u001B[0m \u001B[38;5;124;03m    :rtype: list\u001B[39;00m\n\u001B[1;32m    364\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 365\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [record\u001B[38;5;241m.\u001B[39mvalues(\u001B[38;5;241m*\u001B[39mkeys) \u001B[38;5;28;01mfor\u001B[39;00m record \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m]\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/neo4j/work/result.py:365\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    356\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalues\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mkeys):\n\u001B[1;32m    357\u001B[0m     \u001B[38;5;124;03m\"\"\"Helper function that return the remainder of the result as a list of values lists.\u001B[39;00m\n\u001B[1;32m    358\u001B[0m \n\u001B[1;32m    359\u001B[0m \u001B[38;5;124;03m    See :class:`neo4j.Record.values`\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    363\u001B[0m \u001B[38;5;124;03m    :rtype: list\u001B[39;00m\n\u001B[1;32m    364\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 365\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [record\u001B[38;5;241m.\u001B[39mvalues(\u001B[38;5;241m*\u001B[39mkeys) \u001B[38;5;28;01mfor\u001B[39;00m record \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m]\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/neo4j/work/result.py:187\u001B[0m, in \u001B[0;36mResult.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    185\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_record_buffer\u001B[38;5;241m.\u001B[39mpopleft()\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_streaming:\n\u001B[0;32m--> 187\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_connection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_discarding:\n\u001B[1;32m    189\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_discard()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/neo4j/io/_common.py:186\u001B[0m, in \u001B[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    184\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    185\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 186\u001B[0m         \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    188\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__on_error(exc)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/neo4j/io/_bolt4.py:309\u001B[0m, in \u001B[0;36mBolt4x0.fetch_message\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_server_state_manager\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m ServerStates\u001B[38;5;241m.\u001B[39mFAILED\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 309\u001B[0m     \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_failure\u001B[49m\u001B[43m(\u001B[49m\u001B[43msummary_metadata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ServiceUnavailable, DatabaseUnavailable):\n\u001B[1;32m    311\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/neo4j/io/_common.py:244\u001B[0m, in \u001B[0;36mResponse.on_failure\u001B[0;34m(self, metadata)\u001B[0m\n\u001B[1;32m    242\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(handler):\n\u001B[1;32m    243\u001B[0m     handler()\n\u001B[0;32m--> 244\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m Neo4jError\u001B[38;5;241m.\u001B[39mhydrate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmetadata)\n",
      "\u001B[0;31mClientError\u001B[0m: {code: Neo.ClientError.Procedure.ProcedureCallFailed} {message: Failed to invoke procedure `gds.alpha.pipeline.nodeRegression.addNodeProperty`: Caused by: java.lang.IllegalArgumentException: Could not find a procedure called gds.fastrp.mutate}"
     ]
    }
   ],
   "source": [
    "# Now, let's construct a training pipeline!\n",
    "chameleons_nr_training, _ = gds.alpha.pipeline.nodeRegression.create(\"node_regression_pipeline__Chameleons\")\n",
    "\n",
    "# We configure the splitting\n",
    "chameleons_nr_training.configureSplit(validationFolds=5, testFraction=0.2)\n",
    "\n",
    "# We add a set of model candidates\n",
    "# A linear regression model with the learningRate parameter in a search space\n",
    "chameleons_nr_training.addLinearRegression(\n",
    "    penalty=1e-5,\n",
    "    patience=3,\n",
    "    tolerance=1e-5,\n",
    "    minEpochs=20,\n",
    "    maxEpochs=500,\n",
    "    learningRate={\"range\": [100, 1000]},  # We let the auto-tuner find a good value\n",
    ")\n",
    "# Let's try a few different models\n",
    "chameleons_nr_training.configureAutoTuning(maxTrials=10)\n",
    "\n",
    "# Our input feature dimension is 3132\n",
    "# We can reduce the dimension to speed up training using a FastRP node embedding\n",
    "chameleons_nr_training.addNodeProperty(\n",
    "    \"fastRP\",\n",
    "    embeddingDimension=256,\n",
    "    propertyRatio=0.8,\n",
    "    featureProperties=[\"features_one_hot\"],\n",
    "    mutateProperty=\"frp_embedding\",\n",
    "    randomSeed=420,\n",
    ")\n",
    "\n",
    "# And finally we select what features the model should be using\n",
    "# We rely on the FastRP embedding solely, because it encapsulates the one-hot encoded source features\n",
    "chameleons_nr_training.selectFeatures(\"frp_embedding\")\n",
    "\n",
    "# The training pipeline is now fully configured and ready to be run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the training pipeline to train a model\n",
    "cora_nc_model, train_result = chameleons_nr_training.train(\n",
    "    G_chameleon,  # First, we use the entire Chameleon graph\n",
    "    modelName=\"chameleon_nr_model\",\n",
    "    targetNodeLabels=[\"Chameleon\"],\n",
    "    targetProperty=\"target\",\n",
    "    metrics=[\"MEAN_SQUARED_ERROR\", \"MEAN_ABSOLUTE_ERROR\"],\n",
    "    randomSeed=420,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4342baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Winning model parameters: \\n\\t\\t\" + str(train_result[\"modelInfo\"][\"bestParameters\"]))\n",
    "print()\n",
    "print(\"MEAN_SQUARED_ERROR      test score: \" + str(train_result[\"modelInfo\"][\"metrics\"][\"MEAN_SQUARED_ERROR\"][\"test\"]))\n",
    "print(\"MEAN_ABSOLUTE_ERROR     test score: \" + str(train_result[\"modelInfo\"][\"metrics\"][\"MEAN_ABSOLUTE_ERROR\"][\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0dc05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sample the graph to see if we can get a similarly good model\n",
    "G_chameleon_sample, _ = gds.alpha.graph.sample.rwr(\n",
    "    \"cham_sample\",\n",
    "    G_chameleon,\n",
    "    samplingRatio=0.30,  # We'll use 30% of the graph\n",
    ")\n",
    "\n",
    "# Now we can use the same training pipeline to train another model, but faster!\n",
    "cora_nc_model_sample, train_result_sample = chameleons_nr_training.train(\n",
    "    G_chameleon_sample,\n",
    "    modelName=\"chameleon_nr_model_sample\",\n",
    "    targetNodeLabels=[\"Chameleon\"],\n",
    "    targetProperty=\"target\",\n",
    "    metrics=[\"MEAN_SQUARED_ERROR\", \"MEAN_ABSOLUTE_ERROR\"],\n",
    "    randomSeed=420,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7eabfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Winning model parameters: \\n\\t\\t\" + str(train_result_sample[\"modelInfo\"][\"bestParameters\"]))\n",
    "print()\n",
    "print(\n",
    "    \"MEAN_SQUARED_ERROR      test score: \"\n",
    "    + str(train_result_sample[\"modelInfo\"][\"metrics\"][\"MEAN_SQUARED_ERROR\"][\"test\"])\n",
    ")\n",
    "print(\n",
    "    \"MEAN_ABSOLUTE_ERROR     test score: \"\n",
    "    + str(train_result_sample[\"modelInfo\"][\"metrics\"][\"MEAN_ABSOLUTE_ERROR\"][\"test\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what our models predict\n",
    "\n",
    "# The speed-trained model on 24% training data (30% sample - 20% test set)\n",
    "predicted_targets_sample = cora_nc_model_sample.predict_stream(G_chameleon)\n",
    "# The fully trained model on 80% training data (20% test set)\n",
    "predicted_targets_full = cora_nc_model.predict_stream(G_chameleon)\n",
    "\n",
    "# The original training data for comparison\n",
    "real_targets = gds.graph.nodeProperty.stream(G_chameleon, \"target\")\n",
    "\n",
    "# Merging the data frames\n",
    "merged_full = real_targets.merge(predicted_targets_full, left_on=\"nodeId\", right_on=\"nodeId\")\n",
    "merged_all = merged_full.merge(predicted_targets_sample, left_on=\"nodeId\", right_on=\"nodeId\")\n",
    "\n",
    "# Look at the last 10 rows\n",
    "print(merged_all.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c6875",
   "metadata": {},
   "source": [
    "# And we are done!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
