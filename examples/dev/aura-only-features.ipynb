{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "aura"
    ]
   },
   "source": [
    "# It all starts with AuraDB\n",
    "\n",
    "The new Project 🍓 (Strawberry) is a new way to run GDS on data hosted in an AuraDB database.\n",
    "The way to do this currently in Aura is to copy the database over to an AuraDS instance.\n",
    "This detaches the data and the two databases will likely diverge almost immediately.\n",
    "It also has another couple of limitations:\n",
    "\n",
    "- It's very manual; users have to click in the Aura Console to copy the database\n",
    "- Once GDS computations are finished, writing back to the AuraDB instance is also a manual configuration\n",
    "- AuraDS instances have to be manually managed in the Aura Console and do not encourage users to delete them after usage, thus causing increased running costs\n",
    "\n",
    "With Project 🍓 we're addressing the top two limitations, and alleviating the final one a little bit.\n",
    "\n",
    "## AuraDB\n",
    "\n",
    "A base assumption is that there is an AuraDB already with data in it.\n",
    "In this notebook, we will illustrate just briefly what example data we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to begin, let's make sure we have the correct version of the GDS Python Client installed\n",
    "\n",
    "from graphdatascience import __version__\n",
    "\n",
    "assert __version__ == \"1.9a1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to configure access to our AuraDB instance. Please fill in the instance id and password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_id = \"YOUR_DATABASE_ID\"\n",
    "db_password = \"YOUR_DATABASE_PASSWORD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we connect to the AuraDB instance to and run some preparations for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphdatascience.gds_session.dbms_connection_info import DbmsConnectionInfo\n",
    "import os\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# We need to tell the GDS client that we are working with a devenvironment.\n",
    "# This does not need to be set in production.\n",
    "os.environ[\"AURA_ENV\"] = \"devstrawberryfield\"\n",
    "\n",
    "db_connection_info = DbmsConnectionInfo(\n",
    "    f\"neo4j+s://{db_id}-{os.environ['AURA_ENV']}.databases.neo4j-dev.io\", \"neo4j\", db_password\n",
    ")\n",
    "# start a standard Neo4j Python Driver to connect to the AuraDB instance\n",
    "driver = GraphDatabase.driver(db_connection_info.uri, auth=db_connection_info.auth)\n",
    "\n",
    "# try out our connection\n",
    "with driver.session() as session:\n",
    "    display(session.run(\"RETURN true AS success\").to_df())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some very basic data to our database. \n",
    "The content does not really matter for this notebook, feel free to replace it with more interesting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    session.run(\"CREATE CONSTRAINT users FOR (u:User) REQUIRE u.id IS NODE KEY\")\n",
    "    session.run(\n",
    "        \"\"\"\n",
    "        UNWIND range(0, 999) AS i\n",
    "        CREATE (:User {id: i, age: toInteger(rand() * 75)})\n",
    "        \"\"\"\n",
    "    ).consume()\n",
    "    session.run(\n",
    "        \"\"\"\n",
    "        UNWIND range(1, 8000) AS i\n",
    "        WITH toInteger(rand() * 1000) AS source, toInteger(rand() * 1000) AS target\n",
    "        MATCH (s:User {id: source})\n",
    "        MATCH (t:User {id: target})\n",
    "        CREATE (s)-[:KNOWS {since: 2020 - (rand() * 100)}]->(t)\n",
    "        \"\"\"\n",
    "    ).consume()\n",
    "\n",
    "    print(f\"Number of nodes: {session.run('MATCH () RETURN count(*)').single().value()}\")\n",
    "    print(f\"Number of relationships: {session.run('MATCH ()-->() RETURN count(*)').single().value()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A new database component: Arrow Server\n",
    "\n",
    "We have built a new piece of software into the Neo4j DBMS: an Arrow Server.\n",
    "It is akin to the already existing Bolt and HTTP servers, but it has a very specific purpose: projecting graphs to a remote location, and receiving results to write back to the database.\n",
    "\n",
    "With the Arrow Server comes one crucial new feature: an aggregating projection function.\n",
    "This aggregating function is called `gds.graph.project` and is very similar to Cypher projection v2 in standard GDS.\n",
    "There are three key differences between them:\n",
    "\n",
    "1. In AuraDB, the aggregating function does not take a graph name as a parameter.\n",
    "2. In AuraDB, the aggregating function does not project the graph to the local instance.\n",
    "3. The aggregatoin function should only be called through the python client.\n",
    "\n",
    "The aggregating function is used in queries that look quite identical to those of Cypher projections v2, and are authored by the user.\n",
    "\n",
    "There is another function that comes with the Arrow Server, which is internal, undocumented, but is callable: `internal.arrow.status`.\n",
    "It is used as a crucial part of the GDS Python Client functionality for managing the AuraDB - GDS connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's call this function and see what it returns\n",
    "with driver.session() as session:\n",
    "    display(session.run(\"CALL internal.arrow.status\").to_df())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aura API and GDS Python Client\n",
    "\n",
    "Apart from the extension to AuraDB, we have also added a new API to the GDS Python Client.\n",
    "This API is a Python frontend to the Aura API, as well as a set of internal management features for the AuraDB - GDS connection.\n",
    "In order to use the Aura API, the user needs to have Aura API credentials.\n",
    "These are generated in the Aura Console (under `Account settings`) and are a pair of strings: `CLIENT_ID` and `CLIENT_SECRET`.\n",
    "\n",
    "Using these credentials the full set of features offered by the GDS Python Client can be used.\n",
    "In particular, the features are:\n",
    "\n",
    "- Create a new GDS session\n",
    "- List all existing GDS sessions\n",
    "- (Re-)connect to an existing GDS session\n",
    "- Delete a GDS session\n",
    "\n",
    "We will illustrate what this looks like below.\n",
    "\n",
    "## Tenants\n",
    "\n",
    "If the user is a member of multiple tenants, then they also need to enter their tenant id, in order to disambiguate which tenant they want to use.\n",
    "In this notebook, we will use only a single tenant and omit the tenant id. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise Aura API credentials\n",
    "CLIENT_ID = \"YOUR_AURA_API_CLIENT_ID\"\n",
    "CLIENT_SECRET = \"YOUR_AURA_API_CLIENT_SECRET\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The GDS session\n",
    "\n",
    "A key new concept is the GDS session.\n",
    "This takes the place of an AuraDS instance.\n",
    "(In fact, it is exactly an AuraDS instance at this time, but we don't want to expose that to the user.\n",
    "They should think of it as a GDS session and a separate thing, as much as possible.)\n",
    "The GDS session offers all the GDS functionality that we are familiar with from AuraDS.\n",
    "However, since the idea is to offload database work to AuraDB, the GDS session is not to be considered a database instance.\n",
    "\n",
    "That means that all projections will go from AuraDB to GDS session, not from a co-located database.\n",
    "Similarly, writing back will follow the same path back to AuraDB, and not to a co-located database.\n",
    "\n",
    "## Implementation limitation\n",
    "\n",
    "As mentioned in the parenthesis above, we do make use of existing AuraDS infrastructure to host the GDS sessions.\n",
    "Due to that fact, there actually is a co-located database, but we try to not expose its Bolt URI, in an attempt to prohibit users adding data to that database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The new stuff!\n",
    "from graphdatascience.gds_session.gds_sessions import GdsSessions, AuraAPICredentials\n",
    "\n",
    "# Create a new AuraSessions object\n",
    "sessions = GdsSessions(AuraAPICredentials(CLIENT_ID, CLIENT_SECRET))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing sessions\n",
    "\n",
    "A user can list their running sessions.\n",
    "By default no session is running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions.list_sessions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a new session\n",
    "\n",
    "A user can create a new session by calling `sessions.create_gds`.\n",
    "A session is identified by a name and needs a password to be set. The password is necessary to reconnect to an existing session.\n",
    "Additionally an instance size can be provided. Possible values are  `8GB`, `16GB`, `24GB` (`32GB`, `48GB`, `64GB`, `96GB` are not available in the testing environment).\n",
    "\n",
    "Creating a new session takes a few minutes to complete. We know that this is not ideal and the problem is even exaggerated in the development environment because we do not keep that many cloud VMs running in order to keep costs low.\n",
    "\n",
    "💵💵💵💵💵💵\n",
    "\n",
    "💰💰💰💰💰💰\n",
    "\n",
    "💸💸💸💸💸💸\n",
    "\n",
    "NOTE: the creation of a session marks the start of billable activity.\n",
    "Sessions are machines that run in the cloud, and they cost money.\n",
    "This cost will accumulate for the lifetime of the session, which needs to be manually deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a GDS session!\n",
    "gds = sessions.get_or_create(\"pagerank-compute\", db_connection_info, \"8GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively it is possible to reconnect to an existing session.\n",
    "This is especially handy if the session ran a long computation and the client is disconnected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds = sessions.get_or_create(\"pagerank-compute\", db_connection_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projecting Graphs\n",
    "\n",
    "In order to project graphs from an AuraDB instance into the GDS session we created a new projection method: `gds.graph.project.remoteDb`\n",
    "The projection works similar to Cypher projections V2 and is implemented as an Cypher Aggregation function.\n",
    "The Cypher query containing the projection function is executed on the AuraDB instance and the data it produces is transferred to the \n",
    "GDS session instance via an Arrow connection. \n",
    "\n",
    "There are two key differences between the remote projection and Cypher projections V2:\n",
    "\n",
    "1. In AuraDB, the aggregating function does not take a graph name as a parameter.\n",
    "2. The aggregation function should only be called through the GDS Python Client endpoint `gds.graph.project`\n",
    "\n",
    "### Limitations\n",
    "\n",
    "The aggregation function is currently limited to projecting homogeneous graph schemas. \n",
    "That means that all nodes/relationships will have the same property keys regardless of their labels or type. \n",
    "The caller of the aggregation function must ensure to supply all possible properties for each node or relationship. Null values are not supported.\n",
    "\n",
    "The example data in this notebook contains only `User` nodes with `age` properties.\n",
    "If there are also `Product` nodes with `cost` properties then we would need to add placeholder `cost` and `age` properties on the `User` and `Product` nodes, respectively.\n",
    "This is a limitation we will attempt to address.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, result = gds.graph.project(\n",
    "    \"pagerank-graph\",\n",
    "    \"\"\"\n",
    "    MATCH (u:User) \n",
    "    OPTIONAL MATCH (u)-[r:KNOWS]->(target:User) \n",
    "    RETURN gds.graph.project.remote(u, target, {\n",
    "      sourceNodeProperties: {age: u.age},\n",
    "      targetNodeProperties: {age: target.age},\n",
    "      sourceNodeLabels: labels(u),\n",
    "      targetNodeLabels: labels(target),\n",
    "      relationshipType: 'KNOWS',\n",
    "      relationshipProperties: {since: r.since}\n",
    "    })\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Algorithms\n",
    "\n",
    "Running algorithms on the projected graph works exactly as before, especially when running stream and mutate operations.\n",
    "Mutated algorithm results will be stored in the in-memory graph catalog of the session instance and the data can be retrieved via the stream operations on the graph like `gds.graph.nodeProperty.stream`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running PageRank ...\")\n",
    "pr_result = gds.pageRank.mutate(G, mutateProperty=\"pagerank\")\n",
    "print(f\"Compute millis: {pr_result['computeMillis']}\")\n",
    "print(f\"Node properties written: {pr_result['nodePropertiesWritten']}\")\n",
    "print(f\"Centrality distribution: {pr_result['centralityDistribution']}\")\n",
    "\n",
    "# And then we will run FastRP on that\n",
    "print(\"Running FastRP ...\")\n",
    "frp_result = gds.fastRP.mutate(\n",
    "    G,\n",
    "    mutateProperty=\"fastRP\",\n",
    "    embeddingDimension=64,\n",
    "    featureProperties=[\"pagerank\"],\n",
    "    propertyRatio=0.2,\n",
    "    nodeSelfInfluence=0.2,\n",
    ")\n",
    "print(f\"Compute millis: {frp_result['computeMillis']}\")\n",
    "gds.graph.nodeProperties.stream(G, [\"pagerank\", \"fastRP\"], separate_property_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing back to AuraDB\n",
    "\n",
    "The session's in-memory graph was projected from data in AuraDB.\n",
    "Write back operations will thus persist the data back to the same AuraDB.\n",
    "\n",
    "When calling any write operations the python client will automatically use the new remote write back functionality so that no API changes are necessary.\n",
    "\n",
    "The AuraDB coordinates are not stored in the GDS session, but in the client.\n",
    "Thus, it is important to set up the AuraSessions object with the DB credentials that identify the correct database from which the projection came."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this fails once with some error like \"unable to retrieve routing table\"\n",
    "# then run it again. this is a transient error with a stale server cache.\n",
    "gds.graph.nodeProperties.write(G, \"pagerank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can just use `.write` modes as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.fastRP.write(\n",
    "    G,\n",
    "    writeProperty=\"fastRP\",\n",
    "    embeddingDimension=64,\n",
    "    featureProperties=[\"pagerank\"],\n",
    "    propertyRatio=0.2,\n",
    "    nodeSelfInfluence=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `gds.run_cypher` method to query the updated graph.\n",
    "Note that the `run_query` method will behave differently with the new Aura GDS session. Instead of querying the database that hosts GDS, it will query the *AuraDB* instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    MATCH (u:User) \n",
    "    RETURN u.id, u.age, u.fastRP, u.pagerank AS rank \n",
    "     ORDER BY rank DESC\n",
    "     LIMIT 5\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closing the session\n",
    "\n",
    "Generally we intend for the sessions to only live for the time it takes to run a single workload.\n",
    "If the same workload needs to be re-run, for example to work with updated data, a new session would be created.\n",
    "\n",
    "💵💵💵💵💵💵\n",
    "\n",
    "💰💰💰💰💰💰\n",
    "\n",
    "💸💸💸💸💸💸\n",
    "\n",
    "The `session.delete_gds` operation will delete the session and release all resources associated with it.\n",
    "It is important to note, that until this command was called the customer will be charged for the costs associated with hosting the session instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will return True if it did delete something\n",
    "# it will return False otherwise, but it will not normally fail\n",
    "sessions.delete_gds(\"pagerank-compute\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
