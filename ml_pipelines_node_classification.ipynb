{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nvitucci/graph-data-science-client/blob/add-pipelines-notebook/ml_pipelines_node_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhH0v_bwUrXp"
      },
      "source": [
        "# Machine learning pipelines: node classification example\n",
        "\n",
        "This notebook shows the usage of GDS machine learning pipelines with the Python client and the well-known Cora dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5ttqidnWPTC"
      },
      "source": [
        "## Setup\n",
        "\n",
        "We need an environment where Neo4j and GDS are available, for example AuraDS (which comes with GDS preinstalled) or Neo4j Desktop. \n",
        "\n",
        "Once the credentials to this environment are available, we can install the `graphdatascience` package and create the `gds` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izJD_HlcAdQ0"
      },
      "outputs": [],
      "source": [
        "!pip install graphdatascience==1.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJLQgHK_AghP"
      },
      "outputs": [],
      "source": [
        "# Import the client\n",
        "from graphdatascience import GraphDataScience\n",
        "\n",
        "# Replace with the actual credentials\n",
        "AURA_CONNECTION_URI = \"neo4j+s://xxxxxxxx.databases.neo4j.io\"\n",
        "AURA_USERNAME = \"neo4j\"\n",
        "AURA_PASSWORD = \"\"\n",
        "\n",
        "# Configure the client with AuraDS-recommended settings if using AuraDS\n",
        "gds = GraphDataScience(\n",
        "    AURA_CONNECTION_URI,\n",
        "    auth=(AURA_USERNAME, AURA_PASSWORD),\n",
        "    aura_ds=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOK08QpoWFKv"
      },
      "source": [
        "We import `json` to help in writing the Cypher queries used to load the data, and `numpy` and `pandas` for further data processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ikcvI-cSDoK"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDE2LqTXAmy8"
      },
      "source": [
        "## Load the Cora dataset\n",
        "\n",
        "First of all, we need to load the Cora dataset on Neo4j. Upon loading, we also need to perform an additional preprocessing step to convert the `subject` field (which is a string in the dataset) into an integer, because node properties have to be numerical in order to be projected into a graph; although we could assign consecutive IDs, we assign an ID other than 0 to the first class to show how the classes are represented in the model.\n",
        "\n",
        "Finally, we select a number of nodes to be held out to test the model after it has been trained. This is not related to the algorithm test/split ratio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOZW-I2FBLm_"
      },
      "outputs": [],
      "source": [
        "# TODO: use URLs within the client repo when the notebook is added there\n",
        "CORA_CONTENT = \"https://raw.githubusercontent.com/neo4j/graph-data-science/master/test-utils/src/main/resources/cora.content\"\n",
        "CORA_CITES = \"https://raw.githubusercontent.com/neo4j/graph-data-science/master/test-utils/src/main/resources/cora.cites\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwPI7OHSGj1L"
      },
      "outputs": [],
      "source": [
        "# Using non-consecutive values to show class ordering later on\n",
        "\n",
        "SUBJECT_TO_ID = {\n",
        "    \"Neural_Networks\": 100,\n",
        "    \"Rule_Learning\": 1,\n",
        "    \"Reinforcement_Learning\": 2,\n",
        "    \"Probabilistic_Methods\": 3,\n",
        "    \"Theory\": 4,\n",
        "    \"Genetic_Algorithms\": 5,\n",
        "    \"Case_Based\": 6\n",
        "}\n",
        "\n",
        "HOLDOUT_NODES = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExqLKKQsn9WF"
      },
      "outputs": [],
      "source": [
        "# Define a string representation of the SUBJECT_TO_ID map using backticks\n",
        "subject_map = json.dumps(SUBJECT_TO_ID).replace('\"', '`')\n",
        "\n",
        "print(subject_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_p_Npg3ecyz"
      },
      "outputs": [],
      "source": [
        "# Cypher command to load the nodes using `LOAD CSV`, taking care of\n",
        "# converting the string `subject` field into an integer and\n",
        "# replacing the node label for the holdout nodes\n",
        "load_nodes = f\"\"\"\n",
        "    LOAD CSV FROM \"{CORA_CONTENT}\" AS row\n",
        "    WITH \n",
        "      {subject_map} AS subject_to_id,\n",
        "      toInteger(row[0]) AS extId, \n",
        "      row[1] AS subject, \n",
        "      toIntegerList(row[2..]) AS features\n",
        "    MERGE (p:Paper {{extId: extId, subject: subject_to_id[subject], features: features}})\n",
        "    WITH p LIMIT {HOLDOUT_NODES}\n",
        "    REMOVE p:Paper\n",
        "    SET p:UnclassifiedPaper\n",
        "\"\"\"\n",
        "\n",
        "# Cypher command to load the relationships using `LOAD CSV`\n",
        "load_relationships = f\"\"\"\n",
        "    LOAD CSV FROM \"{CORA_CITES}\" AS row\n",
        "    MATCH (n), (m) \n",
        "    WHERE n.extId = toInteger(row[0]) AND m.extId = toInteger(row[1])\n",
        "    MERGE (n)-[:CITES]->(m)\n",
        "\"\"\"\n",
        "\n",
        "# Load nodes and relationships on Neo4j\n",
        "gds.run_cypher(load_nodes)\n",
        "gds.run_cypher(load_relationships)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmFOLcCunfXB"
      },
      "source": [
        "With the data loaded on Neo4j, we can now project a graph including all the nodes and the `CITES` relationship as undirected (and with `SINGLE` aggregation, to skip repeated relationships as a result of adding the inverse direction)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdMPbSQ9OKZ6"
      },
      "outputs": [],
      "source": [
        "# Create the projected graph containing both classified and unclassified nodes\n",
        "G, _ = gds.graph.project(\n",
        "    \"cora-graph\",\n",
        "    {\n",
        "        \"Paper\": {\n",
        "            \"properties\": [\"features\", \"subject\"]\n",
        "        },\n",
        "        \"UnclassifiedPaper\": {\n",
        "            \"properties\": [\"features\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"CITES\": {\n",
        "            \"orientation\": \"UNDIRECTED\",\n",
        "            \"aggregation\": \"SINGLE\"\n",
        "        }\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGWiTTrGN-Be"
      },
      "source": [
        "## Pipeline catalog basics\n",
        "\n",
        "Once the dataset has been loaded, we can define a node classification machine learning pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP64bLMxN_IB"
      },
      "outputs": [],
      "source": [
        "# Create the pipeline\n",
        "node_pipeline, _ = gds.beta.pipeline.nodeClassification.create(\"cora-pipeline\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jguecWUjQ6DV"
      },
      "outputs": [],
      "source": [
        "# List all pipelines\n",
        "gds.beta.pipeline.list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFy2tMZ5Q7Gd"
      },
      "outputs": [],
      "source": [
        "# List a specific pipeline object\n",
        "gds.beta.pipeline.list(node_pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cil3MMlTtZ7L"
      },
      "source": [
        "## Configure the pipeline\n",
        "\n",
        "We can now configure the pipeline. As a reminder, we need to:\n",
        "\n",
        "1. Select a subset of the available node properties to be used as features for the machine learning model\n",
        "1. Configure the train/test split and the number of folds for k-fold cross-validation _(optional)_\n",
        "1. Configure the candidate models for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcTDdBnxOA0y"
      },
      "outputs": [],
      "source": [
        "# \"Mark\" some node properties that will be used as features\n",
        "node_pipeline.selectFeatures(\n",
        "    [\"features\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8ar00tHEmt5"
      },
      "outputs": [],
      "source": [
        "# If needed, change the train/test split ratio and the number of folds\n",
        "# for k-fold cross-validation\n",
        "node_pipeline.configureSplit(\n",
        "    testFraction=0.2,\n",
        "    validationFolds=5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Jtfr236EO0N"
      },
      "source": [
        "Here we use Logistic Regression as an example for the training, but other algorithms (such as Random Forest) are available as well.\n",
        "\n",
        "Some hyperparameters such as `penalty` can be single values or ranges. If they are expressed as ranges, auto-tuning is used to search their best value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA2jFvx-OHSS"
      },
      "outputs": [],
      "source": [
        "# Add a model candidate to train\n",
        "# Note: penalty can be a single value like 0.0004 or a range\n",
        "node_pipeline.addLogisticRegression(\n",
        "    maxEpochs=1000,\n",
        "    penalty=(0.00038, 0.00042)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFIfl6yYXQgY"
      },
      "source": [
        "## Run the training\n",
        "\n",
        "It is now possible to train the configured models. We also run a training estimate, to make sure there are enough resources to run the actual training afterwards.\n",
        "\n",
        "The Node Classification model supports several evaluation metrics. Here we use the global metric `F1_WEIGHTED`.\n",
        "\n",
        "**NOTE:** The `concurrency` parameter is explicitly set to 4 (the default value) for demonstration purposes. \n",
        "The maximum concurrency in the library is limited to 4 for Neo4j Community Edition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5Eey0EsOXiG"
      },
      "outputs": [],
      "source": [
        "# Estimate the resources needed for training the model\n",
        "node_pipeline.train_estimate(\n",
        "    G,\n",
        "    nodeLabels=[\"Paper\"],\n",
        "    modelName=\"cora-pipeline-model\",\n",
        "    targetProperty=\"subject\",\n",
        "    metrics=[\"F1_WEIGHTED\"],\n",
        "    randomSeed=42,\n",
        "    concurrency=4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GVInjJHwOexk"
      },
      "outputs": [],
      "source": [
        "# Perform the actual training\n",
        "model, stats = node_pipeline.train(\n",
        "    G,\n",
        "    nodeLabels=[\"Paper\"],\n",
        "    modelName=\"cora-pipeline-model\",\n",
        "    targetProperty=\"subject\",\n",
        "    metrics=[\"F1_WEIGHTED\"],\n",
        "    randomSeed=42,\n",
        "    concurrency=4\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxYPHz6seMEn"
      },
      "source": [
        "We can inspect the result of the training, for example to print the evaluation metrics of the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B1pvnkbSZK9A"
      },
      "outputs": [],
      "source": [
        "# Uncomment to print all stats\n",
        "# print(stats.to_json(indent=2))\n",
        "\n",
        "# Print F1_WEIGHTED metric\n",
        "print(stats[\"modelInfo\"][\"metrics\"][\"F1_WEIGHTED\"][\"test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBEfXROYfNES"
      },
      "source": [
        "## Use the model for prediction\n",
        "\n",
        "After the model has been trained, it is possible to use it to classify unclassified data. \n",
        "\n",
        "One simple way to use the `predict` mode is to just stream the result of the prediction. This can be impractical when a graph is very large, so it should be used only for experimentation purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryg5xlPBwE3d"
      },
      "source": [
        "In this example we use the `nodeLabels=[\"UnclassifiedPaper\"]` filter to only run prediction on the unclassified nodes. It must be noted that, when using models that have `nodePropertySteps` that use relationships (such as FastRP and other models that create embeddings, but also algorithms like PageRank), the `nodeLabels` filter should not be used because it would \"cut out\" all the linked nodes that have a different label. We will see an example of this in the following section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "92XksLN9Om4l"
      },
      "outputs": [],
      "source": [
        "predicted = model.predict_stream(\n",
        "    G,\n",
        "    modelName=\"cora-pipeline-model\",\n",
        "    includePredictedProbabilities=True,\n",
        "    nodeLabels=[\"UnclassifiedPaper\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knLyBCSUgR2-"
      },
      "source": [
        "The result of the prediction is a DataFrame containing the predicted class and the predicted probabilities for all the classes for each node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pw5AmIAW7rBT"
      },
      "outputs": [],
      "source": [
        "predicted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ2iADIDgwmH"
      },
      "source": [
        "The order of the classes in the `predictedProbabilities` field is given in the model information, and can be used to retrieve the predicted probability for the predicted class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lbxPNQsg4ByD"
      },
      "outputs": [],
      "source": [
        "classes = stats[\"modelInfo\"][\"classes\"]\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YkkX3JPz7uxA"
      },
      "outputs": [],
      "source": [
        "# Calculate the confidence percentage for the predicted class\n",
        "predicted[\"confidence\"] = predicted.apply(\n",
        "    lambda row: np.floor(row[\"predictedProbabilities\"][classes.index(row[\"predictedClass\"])] * 100), \n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L8pUbVA7-F98"
      },
      "outputs": [],
      "source": [
        "predicted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL7Mi1AIc7OJ"
      },
      "source": [
        "## Adding a data preprocessing step\n",
        "\n",
        "The performance of the model can potentially be increased by adding more features or by using different features altogether. One way is to use models that create embeddings based on both node properties and graph features. One of such models is FastRP, which can be added via the `addNodeProperty` pipeline method.\n",
        "\n",
        "More embedding methods are available in GDS, as well as other pre-processing algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "F_z0gLG9QCAn"
      },
      "outputs": [],
      "source": [
        "node_pipeline_fastrp, _ = gds.beta.pipeline.nodeClassification.create(\"cora-pipeline-fastrp\")\n",
        "\n",
        "# Add a step in the pipeline that mutates the graph\n",
        "node_pipeline_fastrp.addNodeProperty(\n",
        "    \"fastRP\",\n",
        "    mutateProperty=\"embedding\",\n",
        "    embeddingDimension=512,\n",
        "    propertyRatio=1.0,\n",
        "    randomSeed=42,\n",
        "    featureProperties=[\"features\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM51DhPWX4e3"
      },
      "source": [
        "With the node embeddings available as features, we no longer use the original raw `features`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2uQY--MDdePK"
      },
      "outputs": [],
      "source": [
        "node_pipeline_fastrp.selectFeatures(\n",
        "    [\"embedding\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c0krIvXTipcD"
      },
      "outputs": [],
      "source": [
        "# Configure the pipeline as before\n",
        "node_pipeline_fastrp.configureSplit(\n",
        "    testFraction=0.2,\n",
        "    validationFolds=5\n",
        ")\n",
        "\n",
        "node_pipeline_fastrp.addLogisticRegression(\n",
        "    maxEpochs=1000,\n",
        "    penalty=(0.00048, 0.00050)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Kvr9iU4HdoTv"
      },
      "outputs": [],
      "source": [
        "# Perform the actual training\n",
        "model_fastrp, stats_fastrp = node_pipeline_fastrp.train(\n",
        "    G,\n",
        "    nodeLabels=[\"Paper\"],\n",
        "    modelName=\"cora-pipeline-model-fastrp\",\n",
        "    targetProperty=\"subject\",\n",
        "    metrics=[\"F1_WEIGHTED\"],\n",
        "    randomSeed=42,\n",
        "    concurrency=4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_Q3zMmpCd2o0"
      },
      "outputs": [],
      "source": [
        "print(stats_fastrp[\"modelInfo\"][\"metrics\"][\"F1_WEIGHTED\"][\"test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhaPoK0xFdK3"
      },
      "source": [
        "## Use the model for prediction\n",
        "\n",
        "Here we are **not** using the `nodeLabels=[\"UnclassifiedPaper\"]` parameter, because FastRP depends on neighbour nodes. When using models that have `nodePropertySteps` that use relationships (such as FastRP and other models that create embeddings, but also algorithms like PageRank), the `nodeLabels` filter should not be used because it would \"cut out\" all the linked nodes that have a different label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vgfN-ppHw4Rp"
      },
      "outputs": [],
      "source": [
        "predicted_fastrp = model_fastrp.predict_stream(\n",
        "    G,\n",
        "    modelName=\"cora-pipeline-model-fastrp\",\n",
        "    includePredictedProbabilities=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Lp_wzQKdmTDB"
      },
      "outputs": [],
      "source": [
        "predicted_fastrp.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2o_J8dzN-qQ"
      },
      "source": [
        "Since we have used no filters, the `predicted` result contains _all_ the nodes. The way to filter the nodes is via the `streamNodeProperty` method, which can be used only after the new property is written to the graph via the `mutate` mode. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNbRL2y84F6Q"
      },
      "source": [
        "Instead of streaming the results, the prediction can be run in `mutate` mode to be more performant. The predicted nodes can be retrieved using the `streamNodeProperty` method with the `UnclassifiedPaper` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_HVufWHbxIoE"
      },
      "outputs": [],
      "source": [
        "model_fastrp.predict_mutate(\n",
        "    G,\n",
        "    mutateProperty=\"predictedClass\",\n",
        "    modelName=\"cora-pipeline-model-fastrp\",\n",
        "    predictedProbabilityProperty=\"predictedProbabilities\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dSoNCQGjGLKt"
      },
      "outputs": [],
      "source": [
        "predicted_fastrp = gds.graph.streamNodeProperty(\n",
        "    G,\n",
        "    \"predictedClass\",\n",
        "    [\"UnclassifiedPaper\"]\n",
        ")\n",
        "\n",
        "predicted_fastrp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "thVR-anwmmzo"
      },
      "outputs": [],
      "source": [
        "# Retrieve node information from Neo4j using the node IDs from the prediction result\n",
        "nodes = gds.util.asNodes(predicted_fastrp.nodeId.to_list())\n",
        "\n",
        "# Create a new DataFrame containing node IDs along with node properties\n",
        "nodes_df = pd.DataFrame([(node.id, node[\"subject\"]) for node in nodes], columns=[\"nodeId\", \"subject\"])\n",
        "\n",
        "# Merge with the prediction result on node IDs, to check the predicted value\n",
        "# against the original subject\n",
        "#\n",
        "# NOTE: This could also be replaced by just appending `node[\"subject\"]` as a \n",
        "# Series since the node order would not change, but a proper merge (or join) \n",
        "# is clearer and less prone to errors.\n",
        "predicted_fastrp.merge(nodes_df, on=\"nodeId\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z27MnchLr9mi"
      },
      "source": [
        "As we can see, the prediction for all the holdout nodes is accurate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdEVypaiMc5d"
      },
      "source": [
        "## Write result back to Neo4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aKuUQwxbPOaV"
      },
      "outputs": [],
      "source": [
        "model_fastrp.predict_write(\n",
        "    G,\n",
        "    writeProperty=\"predictedSubject\",\n",
        "    modelName=\"cora-pipeline-model-fastrp\",\n",
        "    predictedProbabilityProperty=\"predictedProbabilities\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plRCiikGOofd"
      },
      "source": [
        "## Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFWzcrX3ORXI"
      },
      "outputs": [],
      "source": [
        "model.drop()\n",
        "model_fastrp.drop()\n",
        "node_pipeline.drop()\n",
        "node_pipeline_fastrp.drop()\n",
        "\n",
        "G.drop()\n",
        "gds.run_cypher(\"MATCH (n) DETACH DELETE n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Machine learning pipelines - Node classification example",
      "provenance": [],
      "authorship_tag": "ABX9TyN7QqVTzAahL3BPKHgRt8jS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}